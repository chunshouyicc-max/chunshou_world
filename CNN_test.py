# -*- coding: utf-8 -*-
"""
åŸºäºResNetçš„æ‰‹å†™æ•°å­—è¯†åˆ«ç³»ç»Ÿ - è¶…å¼ºç‰ˆ
ä½¿ç”¨ResNetæ¶æ„å’Œè¿ç§»å­¦ä¹ æŠ€æœ¯
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau
from torchvision import datasets, transforms, models
import numpy as np
import time
import matplotlib.pyplot as plt
from PIL import Image, ImageFilter, ImageEnhance
import os
import argparse
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# 1. é…ç½®å‚æ•° - è¶…å¼ºç‰ˆ
# ==========================================

DEFAULT_IMAGE_PATH = "/home/chunshouy/æ¡Œé¢/1.jpg"
MODEL_WEIGHTS_PATH = "resnet_mnist_best.pth"

# ğŸ”¥ è¶…å¼ºè®­ç»ƒå‚æ•°
BATCH_SIZE = 128
EPOCHS = 50
LEARNING_RATE = 0.1  # é«˜åˆå§‹å­¦ä¹ ç‡
DROPOUT_RATE = 0.5

# ğŸ”¥ è¶…å¼ºæ•°æ®å¢å¼º
ROTATION_RANGE = 45    # æ›´å¤§æ—‹è½¬
TRANSLATE_RANGE = 0.25 # æ›´å¤§å¹³ç§»
SCALE_RANGE = 0.4      # æ›´å¤§ç¼©æ”¾
SHEAR_RANGE = 20       # å‰ªåˆ‡å˜æ¢

# è®¾å¤‡æ£€æµ‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨çš„è®¾å¤‡: {device}")
if device.type == 'cuda':
    print(f"ğŸ’» GPU å‹å·: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
print(f"ğŸ”§ PyTorch ç‰ˆæœ¬: {torch.__version__}")

# ==========================================
# 2. è‡ªå®šä¹‰ResNetæ¨¡å‹ï¼ˆä¸“é—¨ä¸ºMNISTä¼˜åŒ–ï¼‰
# ==========================================

class ResidualBlock(nn.Module):
    """æ®‹å·®å—"""
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                              stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                              stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        
    def forward(self, x):
        residual = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        if self.downsample is not None:
            residual = self.downsample(x)
        
        out += residual
        out = self.relu(out)
        
        return out

class CustomResNet(nn.Module):
    """è‡ªå®šä¹‰ResNetï¼Œä¸“é—¨ä¸º28x28çš„MNISTå›¾åƒä¼˜åŒ–"""
    def __init__(self, block, layers, num_classes=10, dropout_rate=0.5):
        super(CustomResNet, self).__init__()
        
        # åˆå§‹å·ç§¯å±‚ï¼ˆé€‚é…28x28å°å›¾åƒï¼‰
        self.in_channels = 64
        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        # æ®‹å·®å±‚
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        
        # è‡ªé€‚åº”æ± åŒ–å’ŒDropout
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(dropout_rate)
        
        # åˆ†ç±»å™¨
        self.fc = nn.Linear(256, num_classes)
        
        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()
    
    def _make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, 
                         stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for _ in range(1, blocks):
            layers.append(block(out_channels, out_channels))
        
        return nn.Sequential(*layers)
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # åˆå§‹å±‚
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        # æ®‹å·®å±‚
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        
        # æ± åŒ–å’Œåˆ†ç±»
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        x = self.fc(x)
        
        return x

def create_resnet_model(dropout_rate=0.5):
    """åˆ›å»ºResNet-18é£æ ¼æ¨¡å‹"""
    return CustomResNet(ResidualBlock, [2, 2, 2], dropout_rate=dropout_rate)

# ==========================================
# 3. è¶…å¼ºæ•°æ®å¢å¼ºå’ŒåŠ è½½
# ==========================================

def get_ultra_augmentation():
    """è·å–è¶…å¼ºæ•°æ®å¢å¼º"""
    return transforms.Compose([
        # å‡ ä½•å˜æ¢
        transforms.RandomAffine(
            degrees=ROTATION_RANGE,
            translate=(TRANSLATE_RANGE, TRANSLATE_RANGE),
            scale=(1-SCALE_RANGE, 1+SCALE_RANGE),
            shear=SHEAR_RANGE
        ),
        # å¼¹æ€§å˜æ¢
        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),
        # é¢œè‰²å˜æ¢
        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),
        # éšæœºé®æŒ¡
        transforms.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),
        # æ ‡å‡†åŒ–
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,)),
        # æ·»åŠ é«˜æ–¯å™ªå£°
        transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.05)
    ])

def get_data_loaders_ultra():
    """è·å–è¶…å¼ºæ•°æ®åŠ è½½å™¨"""
    print("ğŸ“¥ åŠ è½½MNISTæ•°æ®é›†ï¼ˆè¶…å¼ºå¢å¼ºç‰ˆï¼‰...")
    
    # è®­ç»ƒé›†ä½¿ç”¨è¶…å¼ºå¢å¼º
    train_transform = get_ultra_augmentation()
    
    # æµ‹è¯•é›†è½¬æ¢
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    # åŠ è½½æ•°æ®é›†
    train_dataset = datasets.MNIST(
        root='./data',
        train=True,
        download=True,
        transform=train_transform
    )
    
    test_dataset = datasets.MNIST(
        root='./data',
        train=False,
        download=True,
        transform=test_transform
    )
    
    # åˆ†å‰²è®­ç»ƒéªŒè¯é›†
    train_size = int(0.85 * len(train_dataset))
    val_size = len(train_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        train_dataset, [train_size, val_size]
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=2
    )
    
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=2
    )
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ï¼ˆè¶…å¼ºå¢å¼ºï¼‰:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset):,} å¼ å›¾ç‰‡")
    print(f"  éªŒè¯é›†: {len(val_dataset):,} å¼ å›¾ç‰‡")
    print(f"  æµ‹è¯•é›†: {len(test_dataset):,} å¼ å›¾ç‰‡")
    
    return train_loader, val_loader, test_loader

# ==========================================
# 4. è¶…å¼ºè®­ç»ƒç­–ç•¥
# ==========================================

def train_ultra_model():
    """è¶…å¼ºè®­ç»ƒå‡½æ•°"""
    print("ğŸ”¥ å¼€å§‹è¶…å¼ºè®­ç»ƒï¼ˆResNet + è¶…å¼ºå¢å¼ºï¼‰...")
    start_time = time.time()
    
    # è·å–æ•°æ®
    train_loader, val_loader, test_loader = get_data_loaders_ultra()
    
    # åˆ›å»ºæ¨¡å‹
    model = create_resnet_model(dropout_rate=DROPOUT_RATE).to(device)
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ§® æ¨¡å‹å‚æ•°é‡: {total_params:,} (å¯è®­ç»ƒ: {trainable_params:,})")
    
    # ğŸ”¥ ä½¿ç”¨SGD + å¤§åŠ¨é‡ + æƒé‡è¡°å‡
    optimizer = optim.SGD(
        model.parameters(),
        lr=LEARNING_RATE,
        momentum=0.9,
        weight_decay=5e-4,  # æ›´å¼ºçš„æƒé‡è¡°å‡
        nesterov=True
    )
    
    # ğŸ”¥ OneCycleLRå­¦ä¹ ç‡è°ƒåº¦ï¼ˆæœ€å…ˆè¿›çš„è°ƒåº¦ç­–ç•¥ï¼‰
    scheduler = OneCycleLR(
        optimizer,
        max_lr=LEARNING_RATE,
        epochs=EPOCHS,
        steps_per_epoch=len(train_loader),
        pct_start=0.3,
        anneal_strategy='cos'
    )
    
    # ğŸ”¥ ä½¿ç”¨æ ‡ç­¾å¹³æ»‘çš„äº¤å‰ç†µæŸå¤±
    class LabelSmoothCrossEntropy(nn.Module):
        def __init__(self, smoothing=0.1):
            super().__init__()
            self.smoothing = smoothing
            
        def forward(self, pred, target):
            confidence = 1. - self.smoothing
            logprobs = F.log_softmax(pred, dim=-1)
            nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
            nll_loss = nll_loss.squeeze(1)
            smooth_loss = -logprobs.mean(dim=-1)
            loss = confidence * nll_loss + self.smoothing * smooth_loss
            return loss.mean()
    
    criterion = LabelSmoothCrossEntropy(smoothing=0.1)
    
    # è®­ç»ƒå†å²
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': [],
        'test_acc': [], 'lr_history': []
    }
    
    # æ—©åœå’Œæ¨¡å‹ä¿å­˜
    best_val_acc = 0
    patience = 15
    patience_counter = 0
    best_model_state = None
    
    print(f"ğŸ¯ å¼€å§‹è¶…å¼ºè®­ç»ƒï¼Œå…±{EPOCHS}ä¸ªepoch...")
    print("=" * 80)
    
    for epoch in range(EPOCHS):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            scheduler.step()  # æ¯ä¸ªbatchæ›´æ–°å­¦ä¹ ç‡
            
            train_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            if batch_idx % 50 == 0:
                current_lr = optimizer.param_groups[0]['lr']
                print(f"  Epoch {epoch+1:03d}/{EPOCHS} | "
                      f"Batch {batch_idx:04d}/{len(train_loader):04d} | "
                      f"Loss: {loss.item():.4f} | LR: {current_lr:.6f}")
        
        train_acc = 100. * correct / total
        avg_train_loss = train_loss / len(train_loader)
        
        # ===== éªŒè¯é˜¶æ®µ =====
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                val_loss += criterion(output, target).item()
                _, predicted = output.max(1)
                val_total += target.size(0)
                val_correct += predicted.eq(target).sum().item()
        
        val_acc = 100. * val_correct / val_total
        avg_val_loss = val_loss / len(val_loader)
        
        # ===== è®°å½•å†å² =====
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)
        history['lr_history'].append(optimizer.param_groups[0]['lr'])
        
        # ===== æµ‹è¯•é˜¶æ®µï¼ˆæ¯2ä¸ªepochï¼‰ =====
        if (epoch + 1) % 2 == 0 or epoch == EPOCHS - 1:
            test_acc = evaluate_model(model, test_loader)
            history['test_acc'].append(test_acc)
            test_display = f"æµ‹è¯•: {test_acc:.2f}%"
        else:
            test_display = ""
        
        # æ‰“å°ç»“æœ
        print(f"âœ… Epoch {epoch+1:03d}/{EPOCHS} å®Œæˆ")
        print(f"  è®­ç»ƒ: æŸå¤±={avg_train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
        print(f"  éªŒè¯: æŸå¤±={avg_val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%")
        if test_display:
            print(f"  {test_display}")
        print("-" * 80)
        
        # æ—©åœæ£€æŸ¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
            best_model_state = model.state_dict().copy()
            torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼ŒéªŒè¯å‡†ç¡®ç‡è¿ç»­{patience}ä¸ªepochæœªæå‡")
                break
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # æœ€ç»ˆæµ‹è¯•
    final_test_acc = evaluate_model(model, test_loader)
    
    # è®­ç»ƒæ—¶é—´
    end_time = time.time()
    training_time = end_time - start_time
    
    print(f"\nğŸ¯ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_test_acc:.2f}%")
    print(f"ğŸ¯ æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/60:.1f}åˆ†é’Ÿ)")
    print(f"ğŸ“ˆ è®­ç»ƒè½®æ•°: {epoch+1}/{EPOCHS}")
    
    # ç»˜åˆ¶è¯¦ç»†è®­ç»ƒæ›²çº¿
    plot_ultra_training_curve(history, final_test_acc)
    
    return model, final_test_acc

def evaluate_model(model, data_loader):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
    
    return 100. * correct / total

# ==========================================
# 5. ä¸“å®¶çº§å›¾ç‰‡é¢„å¤„ç†
# ==========================================

def expert_preprocess(image_path):
    """
    ä¸“å®¶çº§å›¾ç‰‡é¢„å¤„ç†
    """
    try:
        # æ‰“å¼€å›¾ç‰‡
        img = Image.open(image_path).convert('L')
        print(f"ğŸ“„ åŸå§‹å›¾ç‰‡: {os.path.basename(image_path)}, å°ºå¯¸: {img.size}")
        
        # ä¿å­˜åŸå§‹å›¾ç‰‡
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 4, 1)
        plt.imshow(img, cmap='gray')
        plt.title('åŸå§‹å›¾ç‰‡')
        plt.axis('off')
        
        # 1. è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆæé«˜å¯¹æ¯”åº¦ï¼‰
        img_array = np.array(img)
        
        # ä½¿ç”¨CLAHEï¼ˆå¯¹æ¯”åº¦å—é™çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰
        try:
            import cv2
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            img_array = clahe.apply(img_array)
        except:
            # å¤‡ç”¨ï¼šæ™®é€šç›´æ–¹å›¾å‡è¡¡åŒ–
            from skimage import exposure
            img_array = exposure.equalize_hist(img_array) * 255
        
        img = Image.fromarray(img_array.astype(np.uint8))
        
        plt.subplot(1, 4, 2)
        plt.imshow(img, cmap='gray')
        plt.title('å¢å¼ºå¯¹æ¯”åº¦')
        plt.axis('off')
        
        # 2. è‡ªé€‚åº”äºŒå€¼åŒ–
        from skimage.filters import threshold_local
        try:
            block_size = 35
            binary_adaptive = img_array > threshold_local(img_array, block_size, offset=10)
            img = Image.fromarray((binary_adaptive * 255).astype(np.uint8))
        except:
            # å¤‡ç”¨ï¼šOtsué˜ˆå€¼
            from skimage.filters import threshold_otsu
            thresh = threshold_otsu(img_array)
            binary = img_array > thresh
            img = Image.fromarray((binary * 255).astype(np.uint8))
        
        # 3. å½¢æ€å­¦æ“ä½œï¼ˆå»å™ªå’Œè¿æ¥ï¼‰
        try:
            import cv2
            kernel = np.ones((2,2), np.uint8)
            img_array = np.array(img)
            img_array = cv2.morphologyEx(img_array, cv2.MORPH_CLOSE, kernel)
            img_array = cv2.morphologyEx(img_array, cv2.MORPH_OPEN, kernel)
            img = Image.fromarray(img_array)
        except:
            pass
        
        # 4. æ‰¾åˆ°æ•°å­—åŒºåŸŸï¼ˆå¸¦æ™ºèƒ½è¾¹è·ï¼‰
        non_zero = np.where(np.array(img) < 250)
        if len(non_zero[0]) > 0:
            min_y, max_y = np.min(non_zero[0]), np.max(non_zero[0])
            min_x, max_x = np.min(non_zero[1]), np.max(non_zero[1])
            
            # è®¡ç®—æ™ºèƒ½è¾¹è·ï¼ˆåŸºäºæ•°å­—å¤§å°ï¼‰
            height = max_y - min_y
            width = max_x - min_x
            margin_ratio = 0.2  # 20%çš„è¾¹è·
            
            margin_y = int(height * margin_ratio)
            margin_x = int(width * margin_ratio)
            
            min_y = max(0, min_y - margin_y)
            max_y = min(img.height, max_y + margin_y)
            min_x = max(0, min_x - margin_x)
            max_x = min(img.width, max_x + margin_x)
            
            img = img.crop((min_x, min_y, max_x, max_y))
        
        plt.subplot(1, 4, 3)
        plt.imshow(img, cmap='gray')
        plt.title('æ•°å­—åŒºåŸŸæå–')
        plt.axis('off')
        
        # 5. è°ƒæ•´å¤§å°ï¼ˆä¿æŒçºµæ¨ªæ¯”ï¼Œå¡«å……åˆ°28x28ï¼‰
        width, height = img.size
        target_size = 24  # å…ˆç¼©æ”¾åˆ°24ï¼Œç„¶åå¡«å……åˆ°28
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = target_size / max(width, height)
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # åˆ›å»º28x28ç”»å¸ƒ
        canvas = Image.new('L', (28, 28), color=0)  # é»‘åº•
        
        # å±…ä¸­æ”¾ç½®
        left = (28 - new_width) // 2
        top = (28 - new_height) // 2
        canvas.paste(img, (left, top))
        
        # 6. æ™ºèƒ½é¢œè‰²åè½¬
        np_canvas = np.array(canvas)
        hist, bins = np.histogram(np_canvas, bins=256, range=(0, 255))
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åè½¬ï¼ˆåŸºäºç›´æ–¹å›¾åˆ†æï¼‰
        dark_pixels = np.sum(hist[:128])  # æš—åƒç´ 
        bright_pixels = np.sum(hist[128:])  # äº®åƒç´ 
        
        if bright_pixels > dark_pixels * 1.5:  # å¦‚æœäº®åƒç´ æ˜æ˜¾å¤šäºæš—åƒç´ 
            canvas = Image.eval(canvas, lambda x: 255 - x)
            print(f"  æ™ºèƒ½é¢œè‰²åè½¬ï¼ˆæš—åƒç´ : {dark_pixels}, äº®åƒç´ : {bright_pixels}ï¼‰")
        
        # 7. é«˜æ–¯æ¨¡ç³Šå»å™ª
        canvas = canvas.filter(ImageFilter.GaussianBlur(radius=0.7))
        
        plt.subplot(1, 4, 4)
        plt.imshow(canvas, cmap='gray')
        plt.title('æœ€ç»ˆé¢„å¤„ç†')
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig('expert_preprocess.png', dpi=120, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ä¸“å®¶çº§é¢„å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º 'expert_preprocess.png'")
        
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        tensor = transform(canvas).unsqueeze(0)
        return tensor
        
    except Exception as e:
        print(f"âŒ ä¸“å®¶çº§é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

# ==========================================
# 6. ç»˜åˆ¶è¶…å¼ºè®­ç»ƒæ›²çº¿
# ==========================================

def plot_ultra_training_curve(history, test_acc):
    """ç»˜åˆ¶è¶…å¼ºè®­ç»ƒæ›²çº¿"""
    try:
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(history['train_loss'], 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±')
        axes[0, 0].plot(history['val_loss'], 'r-', linewidth=2, label='éªŒè¯æŸå¤±')
        axes[0, 0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(history['train_acc'], 'g-', linewidth=2, label='è®­ç»ƒå‡†ç¡®ç‡')
        axes[0, 1].plot(history['val_acc'], 'orange', linewidth=2, label='éªŒè¯å‡†ç¡®ç‡')
        if history['test_acc']:
            test_x = [2*i for i in range(len(history['test_acc']))]
            axes[0, 1].plot(test_x, history['test_acc'], 'r--', linewidth=2, 
                           marker='o', label='æµ‹è¯•å‡†ç¡®ç‡')
        axes[0, 1].axhline(y=test_acc, color='purple', linestyle=':', 
                          linewidth=2, label=f'æœ€ç»ˆæµ‹è¯• ({test_acc:.2f}%)')
        axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy (%)')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡æ›²çº¿
        axes[1, 0].plot(history['lr_history'], 'purple', linewidth=2)
        axes[1, 0].set_title('å­¦ä¹ ç‡å˜åŒ– (OneCycleLR)')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Learning Rate')
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].set_yscale('log')
        
        # å‡†ç¡®ç‡åˆ†å¸ƒ
        axes[1, 1].hist(history['val_acc'], bins=20, alpha=0.7, color='blue', edgecolor='black')
        axes[1, 1].axvline(x=test_acc, color='red', linestyle='--', linewidth=2, 
                          label=f'æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%')
        axes[1, 1].set_title('éªŒè¯å‡†ç¡®ç‡åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('Accuracy (%)')
        axes[1, 1].set_ylabel('Frequency')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('ultra_training_curve.png', dpi=120, bbox_inches='tight')
        plt.close()
        print("ğŸ“ˆ è¶…å¼ºè®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º 'ultra_training_curve.png'")
        
    except Exception as e:
        print(f"âš ï¸ æ— æ³•ç»˜åˆ¶è®­ç»ƒæ›²çº¿: {e}")

# ==========================================
# 7. ä¸»ç¨‹åº
# ==========================================

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ResNetæ‰‹å†™æ•°å­—è¯†åˆ«ç³»ç»Ÿ')
    parser.add_argument('--image', type=str, default=DEFAULT_IMAGE_PATH,
                       help='æ‰‹å†™æ•°å­—å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--train', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹')
    parser.add_argument('--test', action='store_true',
                       help='åªæµ‹è¯•æ¨¡å‹ï¼Œä¸è¯†åˆ«å›¾ç‰‡')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆ15ä¸ªepochï¼‰')
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("=" * 80)
    print("ğŸ”¥ ResNetæ‰‹å†™æ•°å­—è¯†åˆ«ç³»ç»Ÿ - è¶…å¼ºç‰ˆ")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
        torch.backends.cudnn.benchmark = True
    
    # è°ƒæ•´è®­ç»ƒå‚æ•°ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    global EPOCHS
    if args.quick:
        EPOCHS = 15
        print("âš¡ å¿«é€Ÿè®­ç»ƒæ¨¡å¼: 15ä¸ªepoch")
    
    # è®­ç»ƒæˆ–åŠ è½½æ¨¡å‹
    need_train = args.train or not os.path.exists(MODEL_WEIGHTS_PATH)
    
    if need_train:
        print("ğŸ“‚ å¼€å§‹è¶…å¼ºè®­ç»ƒ...")
        try:
            model, test_acc = train_ultra_model()
            print(f"âœ… è¶…å¼ºè®­ç»ƒå®Œæˆï¼Œæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
    else:
        print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {MODEL_WEIGHTS_PATH}")
        model = create_resnet_model().to(device)
        try:
            model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=device))
            model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æµ‹è¯•æ¨¡å‹æ€§èƒ½
            if args.test:
                print("\nğŸ” æµ‹è¯•MNISTæ•°æ®é›†æ€§èƒ½...")
                _, _, test_loader = get_data_loaders_ultra()
                test_acc = evaluate_model(model, test_loader)
                print(f"ğŸ“Š æ¨¡å‹æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%")
                return
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("âš ï¸ å°†é‡æ–°è®­ç»ƒæ¨¡å‹...")
            model, test_acc = train_ultra_model()
    
    # è¯†åˆ«å›¾ç‰‡
    if os.path.exists(args.image):
        print(f"\nğŸ” å¼€å§‹è¯†åˆ«: {os.path.basename(args.image)}")
        
        # é¢„å¤„ç†
        input_tensor = expert_preprocess(args.image)
        if input_tensor is None:
            return
        
        # é¢„æµ‹
        input_tensor = input_tensor.to(device)
        model.eval()
        
        with torch.no_grad():
            output = model(input_tensor)
            probabilities = F.softmax(output, dim=1)
            predicted_class = output.argmax(dim=1).item()
            confidence = probabilities[0, predicted_class].item()
            
            # è·å–æ‰€æœ‰æ¦‚ç‡
            probs = probabilities.squeeze().cpu().numpy()
            sorted_indices = np.argsort(probs)[::-1]
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ¯ ResNetè¯†åˆ«ç»“æœ")
        print("=" * 60)
        print(f"ğŸ“ å›¾ç‰‡: {os.path.basename(args.image)}")
        print(f"ğŸ”¢ é¢„æµ‹æ•°å­—: {predicted_class}")
        print(f"ğŸ† ç½®ä¿¡åº¦: {confidence*100:.1f}%")
        
        if confidence > 0.9:
            print("âœ… çŠ¶æ€: éå¸¸å¯é ")
        elif confidence > 0.7:
            print("âœ… çŠ¶æ€: å¯é ")
        elif confidence > 0.5:
            print("âš ï¸  çŠ¶æ€: ä¸€èˆ¬")
        else:
            print("â“ çŠ¶æ€: ä¸ç¡®å®š")
        
        print("\nğŸ“Š æ¦‚ç‡åˆ†å¸ƒ:")
        for i in range(3):  # æ˜¾ç¤ºå‰3ä¸ª
            idx = sorted_indices[i]
            prob = probs[idx] * 100
            bar = "â–ˆ" * int(prob / 4)
            rank = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i]
            print(f"  {rank} æ•°å­— {idx}: {prob:5.1f}% {bar}")
        
        print("\nğŸ” è¯¦ç»†æ¦‚ç‡:")
        for i in range(10):
            prob = probs[i] * 100
            if prob > 1:
                mark = " â†" if i == predicted_class else ""
                print(f"  æ•°å­— {i}: {prob:5.1f}%{mark}")
        
        print("=" * 60)
        
    else:
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {args.image}")
        print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: python {__file__} --image ä½ çš„å›¾ç‰‡è·¯å¾„")

# ==========================================
# 8. ç¨‹åºå…¥å£
# ==========================================

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()